# Screen Manager Play Audio

* Proposal: [SDL-0288](0288-screen-manager-play-audio.md)
* Author: [Joel Fischer](https://github.com/joeljfischer)
* Status: **Accepted**
* Impacted Platforms: [iOS / Java Suite / JavaScript Suite]

## Introduction
This proposal adds a `playAudio` method (based on the `Speak` RPC) to the screen manager.

## Motivation
The screen manager should be capable of handling all screen related RPCs and features. Template text, template graphics, template soft buttons, menus, and choice interactions are currently handled, but the `Speak` RPC is not.

## Proposed solution
The proposed solution is to add a new private `SDLSpeakManager` sub-manager to the screen manager to handle speak-related capabilities, file uploads, etc. The `SDLScreenManager` itself will then provide a simple public API for playing the audio using the `Speak` RPC.

### Audio Processing
We will add a class that handles initializing the `TTSChunk` related parameters.

##### iOS
```objc
@interface SDLAudioData: NSObject
/**
The underlying prompt generated by the `init`.
*/
@property (nullable, copy, nonatomic, readonly) NSArray<SDLTTSChunk *> *prompt;

/**
If created with an audio file, the audio file that will be uploaded and used.
*/
@property (nullable, copy, nonatomic, readonly) SDLFile *audioFile;

/**
  Initialize with an SDLFile holding data or pointing to a file on the file system. When this object is passed to an `Alert` or `Speak`, the file will be uploaded if it is not already, then played if the system supports that feature.

  Only available on SDL Core 5.0+.

  @param audioFile The audio file to be played by the system
  @param tone Whether or not to play a system tone before the audio file
*/
- (instancetype)initWithAudioFile:(SDLFile *)audioFile;

/**
  Initialize with a string to be spoken by the system speech synthesizer.

  @param spokenString The string to be spoken by the system speech synthesizer
*/
- (instancetype)initWithSpeechSynthesizerString:(NSString *)spokenString;

/**
Initialize with a string to be spoken by the system speech synthesizer using a phonetic string.

@param spokenString The string to be spoken by the system speech synthesizer
@param phoneticType Must be one of `SAPI_PHONEMES`, `LHPLUS_PHONEMES`, `TEXT`, or `PRE_RECORDED` or no object will be created
@param tone Whether or not to play a system tone before the synthesized speech
*/
- (instancetype)initWithPhoneticSpeechSynthesizerString:(NSString *)phoneticString phoneticType:(SDLSpeechCapabilities)phoneticType;
```

##### Java
```java
public class AudioData {
   private List<TTSChunk> prompt;
   private SdlFile audioFile;

   // All vars have getters as well but no setters

   AudioData(@NonNull SdlFile audioFile)
   AudioData(@NonNull String spokenString)
   AudioData(@NonNull String phoneticString, @NonNull SpeechCapabilities phoneticType)
}
```

### Screen Manager API
Next is the addition to the screen manager public API itself to play the audio data.

##### iOS
```objc
@interface SDLScreenManager: NSObject
// Everything already there

/**
Play some audio on the module.

If the audio contains a file that needs to be uploaded, the file will be uploaded before it is played.

The handler will be called when the module responds to the request to play.
*/
- (void)playAudio:(NSArray<SDLAudioData *> *)audioData withCompletionHandler:(SDLScreenManagerUpdateCompletionHandler)handler;

@end
```

##### Java
```java
public class BaseScreenManager {
    // Everything already there
    public void playAudio(List<AudioData> audioData, CompletionListener listener)
}
```

### JavaScript Suite APIs
Due to the size of the iOS APIs and the similarity between the iOS, Java Suite and eventual JavaScript Suite APIs, this proposal does not present the public APIs of the JavaScript Suite APIs â€“ especially because the JavaScript Suite APIs do not currently have a screen manager layer. The JavaScript Suite APIs should mirror the iOS and Java Suite API appropriately and is up to the Project Maintainer's discretion. However, if any changes needed to be made such that they impacted the iOS / Java Suite API (such as the alteration, addition, or removal of a method or property), then a proposal revision would be needed.

### General Notes

#### Handling Multiple playAudio Calls
There are two general possibilities for how to handle if the developer calls `playAudio` while another piece of audio is playing.

1. We could queue the next `playAudio` and wait for the first to finish. We would use a queueing system similar to the `ChoiceSetManager` for this.
2. We could send the next `playAudio` `Speak` RPC immediately and allow the head unit to handle playing it after the first, or, more likely, error and then return the error.

Between these two options, this proposal uses option #1 above, option #2 is noted below as "Alternatives Considered" #2.

## Potential Downsides
This adds some complexity by needing to handle file uploads for possible `TTSChunk` file uploads. However, this is complexity that must currently be handled by the developer.

## Impact on Existing Code
This will be a minor version change for all app libraries.

## Alternatives Considered
1. We could move `playAudio` to the `SDLManager` instead of the `ScreenManager` because it doesn't _technically_ change the screen. However, the `ScreenManager` is already set up for sub-managers, which this will use. Furthermore, the developer usually looks on the `ScreenManager` for their primary app implementation.
2. We could implement "Handling Multiple playAudio Calls" option #2 instead of option #1, but the developer will need to track the responses of their `playAudio` calls manually to ensure there are no conflicts.
